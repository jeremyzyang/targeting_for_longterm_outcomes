{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d099d7-ea80-4d58-aa26-9d5cc9b404b3",
   "metadata": {},
   "source": [
    "## cross-fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4edd7d-99d9-446e-8d7b-340834f93fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7bd9384-4d94-44a4-b82d-d05f664ccbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/export/projects2/jeryang_narrative_project/globe/log'\n",
    "os.chdir(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b660e4-fae9-47a6-84f6-9fd7d2c77b88",
   "metadata": {},
   "source": [
    "### first experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe2eabd-8344-49fe-b46b-1197f561ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./df_exp1.csv')\n",
    "df1 = df1.sort_values('subscriber_id')\n",
    "\n",
    "df1_s = pd.read_csv('./df_surrogate_exp1.csv')\n",
    "df1_s = df1_s.sort_values('subscriber_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "983ca0ed-563a-4341-bc86-b089154089d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate an outcome model\n",
    "Y = df1_s['rev3'].values # for 3-year revenue\n",
    "\n",
    "#Y = df1_s['rev'].values # for 18-month revenue\n",
    "\n",
    "#Y = df1_s['rev_6'].values # for surrogate index on 18-month revenue constructed with surrogates in the first 6 months\n",
    "#Y = df1_s['rev_5'].values # for surrogate index on 18-month revenue constructed with surrogates in the first 5 months\n",
    "#Y = df1_s['rev_4'].values # for surrogate index on 18-month revenue constructed with surrogates in the first 4 months\n",
    "#Y = df1_s['rev_3'].values # for surrogate index on 18-month revenue constructed with surrogates in the first 3 months\n",
    "#Y = df1_s['rev_2'].values # for surrogate index on 18-month revenue constructed with surrogates in the first 2 months\n",
    "#Y = df1_s['rev_1'].values # for surrogate index on 18-month revenue constructed with surrogates in the first 1 month\n",
    "\n",
    "#Y = df1_s['rev_m6'].values # for 6-month revenue\n",
    "#Y = df1_s['rev_m5'].values # for 5-month revenue\n",
    "#Y = df1_s['rev_m4'].values # for 4-month revenue\n",
    "#Y = df1_s['rev_m3'].values # for 3-month revenue\n",
    "#Y = df1_s['rev_m2'].values # for 2-month revenue\n",
    "#Y = df1_s['rev_m1'].values # for 1-month revenue\n",
    "\n",
    "ind = df1['subscriber_id'].values\n",
    "p = df1['p_treated'].values\n",
    "T = df1['treated'].values\n",
    "\n",
    "df_est = df1.drop(columns=['subscriber_id', 'regi_user_key',\n",
    "                 'treated', 'churn', 'time', \n",
    "                 'rev', 'rev1', 'rev2', 'rev3', 'subscription_status', 'last_stop_date'])\n",
    "\n",
    "X1 = df_est[df_est.columns[df_est.dtypes != 'object']].values\n",
    "X2 = pd.get_dummies(df_est,prefix=df_est.columns[df_est.dtypes == 'object']).values\n",
    "X = np.column_stack((X1,X2))\n",
    "X = np.nan_to_num(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d440fd-5fc7-4b9f-8053-482269db3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_est = np.column_stack((Y,T,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ef2d62-46ff-48a2-8549-c18b489f4b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.05547424e+02, 0.00000000e+00, 3.90000000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.86307129e+02, 0.00000000e+00, 4.60000000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [9.12008484e+02, 0.00000000e+00, 1.56000000e+02, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [8.74160767e+01, 0.00000000e+00, 4.05900000e+04, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [7.88006897e+02, 0.00000000e+00, 4.06320000e+04, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.21595581e+02, 0.00000000e+00, 4.06330000e+04, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30cfd106-76ce-45c8-a9ca-c80298563f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # number of cross-fitting folds\n",
    "\n",
    "df_n = np.array_split(df_est, n)\n",
    "\n",
    "mu = {}\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    df_train = np.vstack(np.delete(df_n, i)) # use -i folds to train the model \n",
    "    df_est = df_n[i] \n",
    "    \n",
    "    df_train0 = df_train[df_train[:,1] == 0] # separate the training data by action (treated = 0 or 1)\n",
    "    df_train1 = df_train[df_train[:,1] == 1]\n",
    "    \n",
    "    df_train_y0 = df_train0[:,0]\n",
    "    df_train_y1 = df_train1[:,0]\n",
    "    \n",
    "    df_train_x0 = df_train0[:,2:]\n",
    "    df_train_x1 = df_train1[:,2:]\n",
    "    \n",
    "    model0 = xgb.XGBRegressor(objective=\"reg:squarederror\", learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "    model1 = xgb.XGBRegressor(objective=\"reg:squarederror\", learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "    \n",
    "    model0.fit(df_train_x0, df_train_y0)\n",
    "    model1.fit(df_train_x1, df_train_y1)\n",
    "    \n",
    "    mu0 = model0.predict(df_est[:,2:]) # using the trained model to predict on the ith fold\n",
    "    mu1 = model1.predict(df_est[:,2:])  \n",
    "    \n",
    "    mu[i] = np.stack((mu0, mu1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb18d67b-45bf-46a2-b0c7-ccd2b30d2099",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.column_stack((mu[0],mu[1],mu[2]))\n",
    "mu = np.transpose(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d43b3c-2fa5-4a85-9f25-6e025a77ae1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[775.7561 , 374.27005],\n",
       "       [751.1249 , 745.0304 ],\n",
       "       [689.084  , 702.1704 ],\n",
       "       ...,\n",
       "       [575.2128 , 700.2734 ],\n",
       "       [564.3778 , 302.9008 ],\n",
       "       [521.2075 , 649.86346]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu # the columns are predicted y0 and y1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c26d3-b014-4106-a88d-a2720621adaf",
   "metadata": {},
   "source": [
    "### second experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "327ea58d-b5e1-41ed-9dd8-0cf69bf650d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('./df_exp2.csv')\n",
    "df2_s = pd.read_csv('./df_surrogate_exp2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8339f488-bea1-425b-8af0-e0db60832ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df2_s['rev3'].values\n",
    "ind = df2['subscriber_id'].values\n",
    "p = df2['prob'].values\n",
    "T = df2['condition'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df14cdc3-e95b-4547-9996-84b132f872dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_est = df2.drop(columns=['subscriber_id', \n",
    "                 'treated', 'churn', 'time', 'condition', 'prob', 'hte', 'action', 'score_c', 'rev1', \n",
    "                 'rev','subscription_status','score_discrete'])\n",
    "\n",
    "X1 = df2[df2.columns[df2.dtypes != 'object']].values\n",
    "X2 = pd.get_dummies(df2,prefix=df2.columns[df2.dtypes == 'object']).values\n",
    "X = np.column_stack((X1,X2))\n",
    "X = np.nan_to_num(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05bd80ea-fef4-4b95-87f6-cb9337e341fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_est = np.column_stack((Y,T,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d6edec2-1fcf-4f85-a256-4dd054956089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[802.850710362645, 'control', 1.0, ..., 0.0, 0.0, 0.0],\n",
       "       [1302.83643412332, 'control', 2.0, ..., 0.0, 0.0, 0.0],\n",
       "       [844.195749983284, 'control', 3.0, ..., 0.0, 0.0, 0.0],\n",
       "       ...,\n",
       "       [686.74324533559, '$5.99/8 weeks', 95552.0, ..., 0.0, 0.0, 0.0],\n",
       "       [778.821398417977, 'control', 95553.0, ..., 0.0, 0.0, 0.0],\n",
       "       [778.527627748459, 'control', 95554.0, ..., 0.0, 0.0, 0.0]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ec51285-ab16-4454-8e2f-876fb2ebc801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 3 # number of cross-fitting folds\n",
    "\n",
    "df_n = np.array_split(df_est, n)\n",
    "\n",
    "mu = {}\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    df_train = np.vstack(np.delete(df_n, i)) # use -i folds to train the model \n",
    "    df_est = df_n[i] \n",
    "    \n",
    "    df_train0 = df_train[df_train[:,1] == 'control'] # separate the training data by action \n",
    "    df_train1 = df_train[df_train[:,1] == 'gift card']\n",
    "    df_train2 = df_train[df_train[:,1] == 'thank you email only']\n",
    "    df_train3 = df_train[df_train[:,1] == '$3.99/8 weeks']\n",
    "    df_train4 = df_train[df_train[:,1] == '$4.99/8 weeks']\n",
    "    df_train5 = df_train[df_train[:,1] == '$5.99/8 weeks']\n",
    "    df_train6 = df_train[df_train[:,1] == '$5.99/4 weeks']\n",
    "    \n",
    "    df_train_y0 = df_train0[:,0]\n",
    "    df_train_y1 = df_train1[:,0]\n",
    "    df_train_y2 = df_train2[:,0]\n",
    "    df_train_y3 = df_train3[:,0]\n",
    "    df_train_y4 = df_train4[:,0]\n",
    "    df_train_y5 = df_train5[:,0]\n",
    "    df_train_y6 = df_train6[:,0]\n",
    "    \n",
    "    df_train_x0 = df_train0[:,2:]\n",
    "    df_train_x1 = df_train1[:,2:]\n",
    "    df_train_x2 = df_train2[:,2:]\n",
    "    df_train_x3 = df_train3[:,2:]\n",
    "    df_train_x4 = df_train4[:,2:]\n",
    "    df_train_x5 = df_train5[:,2:]\n",
    "    df_train_x6 = df_train6[:,2:]\n",
    "    \n",
    "    model0 = xgb.XGBRegressor(objective=\"reg:squarederror\", learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "    model1 = xgb.XGBRegressor(objective=\"reg:squarederror\", learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "    model2 = xgb.XGBRegressor(objective=\"reg:squarederror\", learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "    model3 = xgb.XGBRegressor(objective=\"reg:squarederror\", learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "    model4 = xgb.XGBRegressor(objective=\"reg:squarederror\", learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "    model5 = xgb.XGBRegressor(objective=\"reg:squarederror\", learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "    model6 = xgb.XGBRegressor(objective=\"reg:squarederror\", learning_rate = 0.1,max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "\n",
    "    model0.fit(df_train_x0, df_train_y0)\n",
    "    model1.fit(df_train_x1, df_train_y1)\n",
    "    model2.fit(df_train_x2, df_train_y2)\n",
    "    model3.fit(df_train_x3, df_train_y3)\n",
    "    model4.fit(df_train_x4, df_train_y4)\n",
    "    model5.fit(df_train_x5, df_train_y5)\n",
    "    model6.fit(df_train_x6, df_train_y6)\n",
    "    \n",
    "    mu0 = model0.predict(df_est[:,2:]) # using the trained model to predict on the ith fold\n",
    "    mu1 = model1.predict(df_est[:,2:])  \n",
    "    mu2 = model2.predict(df_est[:,2:]) \n",
    "    mu3 = model3.predict(df_est[:,2:])  \n",
    "    mu4 = model4.predict(df_est[:,2:])  \n",
    "    mu5 = model5.predict(df_est[:,2:]) \n",
    "    mu6 = model6.predict(df_est[:,2:])  \n",
    "    \n",
    "    mu[i] = np.stack((mu0, mu1, mu2, mu3, mu4, mu5, mu6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "892ff1a9-a786-45a8-97b8-37463403fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.column_stack((mu[0],mu[1],mu[2]))\n",
    "mu = np.transpose(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d1afd58-ba95-49f1-acd4-b03bc8d5f224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 822.3403 ,  536.0684 ,  858.39404, ...,  600.83813,  762.11475,\n",
       "         814.8152 ],\n",
       "       [ 944.4714 ,  533.451  , 1107.6703 , ..., 1264.919  ,  912.13306,\n",
       "         741.6337 ],\n",
       "       [ 827.1564 ,  533.2358 ,  968.63293, ..., 1174.4739 ,  869.001  ,\n",
       "         785.72064],\n",
       "       ...,\n",
       "       [ 872.9984 ,  444.99426, 1021.24713, ...,  534.91907,  654.7807 ,\n",
       "         947.27124],\n",
       "       [ 822.2045 ,  446.55606,  742.58563, ...,  609.23444,  799.2239 ,\n",
       "         857.54456],\n",
       "       [ 829.71155,  453.30045,  800.1953 , ...,  615.69403,  801.4896 ,\n",
       "         886.19696]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu # the columns are predicted y0,y1,y2,y3,y4,y5,y6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
